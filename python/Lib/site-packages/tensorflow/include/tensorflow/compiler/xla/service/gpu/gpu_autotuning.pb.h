// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow/compiler/xla/service/gpu/gpu_autotuning.proto

#ifndef GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcompiler_2fxla_2fservice_2fgpu_2fgpu_5fautotuning_2eproto
#define GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcompiler_2fxla_2fservice_2fgpu_2fgpu_5fautotuning_2eproto

#include <limits>
#include <string>

#include <google/protobuf/port_def.inc>
#if PROTOBUF_VERSION < 3009000
#error This file was generated by a newer version of protoc which is
#error incompatible with your Protocol Buffer headers. Please update
#error your headers.
#endif
#if 3009002 < PROTOBUF_MIN_PROTOC_VERSION
#error This file was generated by an older version of protoc which is
#error incompatible with your Protocol Buffer headers. Please
#error regenerate this file with a newer version of protoc.
#endif

#include <google/protobuf/port_undef.inc>
#include <google/protobuf/io/coded_stream.h>
#include <google/protobuf/arena.h>
#include <google/protobuf/arenastring.h>
#include <google/protobuf/generated_message_table_driven.h>
#include <google/protobuf/generated_message_util.h>
#include <google/protobuf/inlined_string_field.h>
#include <google/protobuf/metadata.h>
#include <google/protobuf/generated_message_reflection.h>
#include <google/protobuf/message.h>
#include <google/protobuf/repeated_field.h>  // IWYU pragma: export
#include <google/protobuf/extension_set.h>  // IWYU pragma: export
#include <google/protobuf/unknown_field_set.h>
#include "tensorflow/compiler/xla/service/hlo.pb.h"
#include "tensorflow/compiler/xla/xla_data.pb.h"
#include "tensorflow/core/protobuf/autotuning.pb.h"
// @@protoc_insertion_point(includes)
#include <google/protobuf/port_def.inc>
#define PROTOBUF_INTERNAL_EXPORT_tensorflow_2fcompiler_2fxla_2fservice_2fgpu_2fgpu_5fautotuning_2eproto
PROTOBUF_NAMESPACE_OPEN
namespace internal {
class AnyMetadata;
}  // namespace internal
PROTOBUF_NAMESPACE_CLOSE

// Internal implementation detail -- do not use these members.
struct TableStruct_tensorflow_2fcompiler_2fxla_2fservice_2fgpu_2fgpu_5fautotuning_2eproto {
  static const ::PROTOBUF_NAMESPACE_ID::internal::ParseTableField entries[]
    PROTOBUF_SECTION_VARIABLE(protodesc_cold);
  static const ::PROTOBUF_NAMESPACE_ID::internal::AuxillaryParseTableField aux[]
    PROTOBUF_SECTION_VARIABLE(protodesc_cold);
  static const ::PROTOBUF_NAMESPACE_ID::internal::ParseTable schema[4]
    PROTOBUF_SECTION_VARIABLE(protodesc_cold);
  static const ::PROTOBUF_NAMESPACE_ID::internal::FieldMetadata field_metadata[];
  static const ::PROTOBUF_NAMESPACE_ID::internal::SerializationTable serialization_table[];
  static const ::PROTOBUF_NAMESPACE_ID::uint32 offsets[];
};
extern const ::PROTOBUF_NAMESPACE_ID::internal::DescriptorTable descriptor_table_tensorflow_2fcompiler_2fxla_2fservice_2fgpu_2fgpu_5fautotuning_2eproto;
namespace xla {
namespace gpu {
class AlgorithmBlacklist;
class AlgorithmBlacklistDefaultTypeInternal;
extern AlgorithmBlacklistDefaultTypeInternal _AlgorithmBlacklist_default_instance_;
class AlgorithmBlacklistEntry;
class AlgorithmBlacklistEntryDefaultTypeInternal;
extern AlgorithmBlacklistEntryDefaultTypeInternal _AlgorithmBlacklistEntry_default_instance_;
class BlacklistedAlgorithm;
class BlacklistedAlgorithmDefaultTypeInternal;
extern BlacklistedAlgorithmDefaultTypeInternal _BlacklistedAlgorithm_default_instance_;
class ConvInstructionLog;
class ConvInstructionLogDefaultTypeInternal;
extern ConvInstructionLogDefaultTypeInternal _ConvInstructionLog_default_instance_;
}  // namespace gpu
}  // namespace xla
PROTOBUF_NAMESPACE_OPEN
template<> ::xla::gpu::AlgorithmBlacklist* Arena::CreateMaybeMessage<::xla::gpu::AlgorithmBlacklist>(Arena*);
template<> ::xla::gpu::AlgorithmBlacklistEntry* Arena::CreateMaybeMessage<::xla::gpu::AlgorithmBlacklistEntry>(Arena*);
template<> ::xla::gpu::BlacklistedAlgorithm* Arena::CreateMaybeMessage<::xla::gpu::BlacklistedAlgorithm>(Arena*);
template<> ::xla::gpu::ConvInstructionLog* Arena::CreateMaybeMessage<::xla::gpu::ConvInstructionLog>(Arena*);
PROTOBUF_NAMESPACE_CLOSE
namespace xla {
namespace gpu {

// ===================================================================

class ConvInstructionLog :
    public ::PROTOBUF_NAMESPACE_ID::Message /* @@protoc_insertion_point(class_definition:xla.gpu.ConvInstructionLog) */ {
 public:
  ConvInstructionLog();
  virtual ~ConvInstructionLog();

  ConvInstructionLog(const ConvInstructionLog& from);
  ConvInstructionLog(ConvInstructionLog&& from) noexcept
    : ConvInstructionLog() {
    *this = ::std::move(from);
  }

  inline ConvInstructionLog& operator=(const ConvInstructionLog& from) {
    CopyFrom(from);
    return *this;
  }
  inline ConvInstructionLog& operator=(ConvInstructionLog&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }

  static const ::PROTOBUF_NAMESPACE_ID::Descriptor* descriptor() {
    return GetDescriptor();
  }
  static const ::PROTOBUF_NAMESPACE_ID::Descriptor* GetDescriptor() {
    return GetMetadataStatic().descriptor;
  }
  static const ::PROTOBUF_NAMESPACE_ID::Reflection* GetReflection() {
    return GetMetadataStatic().reflection;
  }
  static const ConvInstructionLog& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const ConvInstructionLog* internal_default_instance() {
    return reinterpret_cast<const ConvInstructionLog*>(
               &_ConvInstructionLog_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    0;

  friend void swap(ConvInstructionLog& a, ConvInstructionLog& b) {
    a.Swap(&b);
  }
  inline void Swap(ConvInstructionLog* other) {
    if (other == this) return;
    InternalSwap(other);
  }

  // implements Message ----------------------------------------------

  inline ConvInstructionLog* New() const final {
    return CreateMaybeMessage<ConvInstructionLog>(nullptr);
  }

  ConvInstructionLog* New(::PROTOBUF_NAMESPACE_ID::Arena* arena) const final {
    return CreateMaybeMessage<ConvInstructionLog>(arena);
  }
  void CopyFrom(const ::PROTOBUF_NAMESPACE_ID::Message& from) final;
  void MergeFrom(const ::PROTOBUF_NAMESPACE_ID::Message& from) final;
  void CopyFrom(const ConvInstructionLog& from);
  void MergeFrom(const ConvInstructionLog& from);
  PROTOBUF_ATTRIBUTE_REINITIALIZES void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  #if GOOGLE_PROTOBUF_ENABLE_EXPERIMENTAL_PARSER
  const char* _InternalParse(const char* ptr, ::PROTOBUF_NAMESPACE_ID::internal::ParseContext* ctx) final;
  #else
  bool MergePartialFromCodedStream(
      ::PROTOBUF_NAMESPACE_ID::io::CodedInputStream* input) final;
  #endif  // GOOGLE_PROTOBUF_ENABLE_EXPERIMENTAL_PARSER
  void SerializeWithCachedSizes(
      ::PROTOBUF_NAMESPACE_ID::io::CodedOutputStream* output) const final;
  ::PROTOBUF_NAMESPACE_ID::uint8* InternalSerializeWithCachedSizesToArray(
      ::PROTOBUF_NAMESPACE_ID::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  inline void SharedCtor();
  inline void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(ConvInstructionLog* other);
  friend class ::PROTOBUF_NAMESPACE_ID::internal::AnyMetadata;
  static ::PROTOBUF_NAMESPACE_ID::StringPiece FullMessageName() {
    return "xla.gpu.ConvInstructionLog";
  }
  private:
  inline ::PROTOBUF_NAMESPACE_ID::Arena* GetArenaNoVirtual() const {
    return nullptr;
  }
  inline void* MaybeArenaPtr() const {
    return nullptr;
  }
  public:

  ::PROTOBUF_NAMESPACE_ID::Metadata GetMetadata() const final;
  private:
  static ::PROTOBUF_NAMESPACE_ID::Metadata GetMetadataStatic() {
    ::PROTOBUF_NAMESPACE_ID::internal::AssignDescriptors(&::descriptor_table_tensorflow_2fcompiler_2fxla_2fservice_2fgpu_2fgpu_5fautotuning_2eproto);
    return ::descriptor_table_tensorflow_2fcompiler_2fxla_2fservice_2fgpu_2fgpu_5fautotuning_2eproto.file_level_metadata[kIndexInFileMessages];
  }

  public:

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  enum : int {
    kOperandShapesFieldNumber = 2,
    kOperandAddressesFieldNumber = 4,
    kInstructionFieldNumber = 1,
    kResultAddressFieldNumber = 3,
  };
  // repeated .xla.ShapeProto operand_shapes = 2;
  int operand_shapes_size() const;
  void clear_operand_shapes();
  ::xla::ShapeProto* mutable_operand_shapes(int index);
  ::PROTOBUF_NAMESPACE_ID::RepeatedPtrField< ::xla::ShapeProto >*
      mutable_operand_shapes();
  const ::xla::ShapeProto& operand_shapes(int index) const;
  ::xla::ShapeProto* add_operand_shapes();
  const ::PROTOBUF_NAMESPACE_ID::RepeatedPtrField< ::xla::ShapeProto >&
      operand_shapes() const;

  // repeated uint64 operand_addresses = 4;
  int operand_addresses_size() const;
  void clear_operand_addresses();
  ::PROTOBUF_NAMESPACE_ID::uint64 operand_addresses(int index) const;
  void set_operand_addresses(int index, ::PROTOBUF_NAMESPACE_ID::uint64 value);
  void add_operand_addresses(::PROTOBUF_NAMESPACE_ID::uint64 value);
  const ::PROTOBUF_NAMESPACE_ID::RepeatedField< ::PROTOBUF_NAMESPACE_ID::uint64 >&
      operand_addresses() const;
  ::PROTOBUF_NAMESPACE_ID::RepeatedField< ::PROTOBUF_NAMESPACE_ID::uint64 >*
      mutable_operand_addresses();

  // .xla.HloInstructionProto instruction = 1;
  bool has_instruction() const;
  void clear_instruction();
  const ::xla::HloInstructionProto& instruction() const;
  ::xla::HloInstructionProto* release_instruction();
  ::xla::HloInstructionProto* mutable_instruction();
  void set_allocated_instruction(::xla::HloInstructionProto* instruction);

  // uint64 result_address = 3;
  void clear_result_address();
  ::PROTOBUF_NAMESPACE_ID::uint64 result_address() const;
  void set_result_address(::PROTOBUF_NAMESPACE_ID::uint64 value);

  // @@protoc_insertion_point(class_scope:xla.gpu.ConvInstructionLog)
 private:
  class _Internal;

  ::PROTOBUF_NAMESPACE_ID::internal::InternalMetadataWithArena _internal_metadata_;
  ::PROTOBUF_NAMESPACE_ID::RepeatedPtrField< ::xla::ShapeProto > operand_shapes_;
  ::PROTOBUF_NAMESPACE_ID::RepeatedField< ::PROTOBUF_NAMESPACE_ID::uint64 > operand_addresses_;
  mutable std::atomic<int> _operand_addresses_cached_byte_size_;
  ::xla::HloInstructionProto* instruction_;
  ::PROTOBUF_NAMESPACE_ID::uint64 result_address_;
  mutable ::PROTOBUF_NAMESPACE_ID::internal::CachedSize _cached_size_;
  friend struct ::TableStruct_tensorflow_2fcompiler_2fxla_2fservice_2fgpu_2fgpu_5fautotuning_2eproto;
};
// -------------------------------------------------------------------

class BlacklistedAlgorithm :
    public ::PROTOBUF_NAMESPACE_ID::Message /* @@protoc_insertion_point(class_definition:xla.gpu.BlacklistedAlgorithm) */ {
 public:
  BlacklistedAlgorithm();
  virtual ~BlacklistedAlgorithm();

  BlacklistedAlgorithm(const BlacklistedAlgorithm& from);
  BlacklistedAlgorithm(BlacklistedAlgorithm&& from) noexcept
    : BlacklistedAlgorithm() {
    *this = ::std::move(from);
  }

  inline BlacklistedAlgorithm& operator=(const BlacklistedAlgorithm& from) {
    CopyFrom(from);
    return *this;
  }
  inline BlacklistedAlgorithm& operator=(BlacklistedAlgorithm&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }

  static const ::PROTOBUF_NAMESPACE_ID::Descriptor* descriptor() {
    return GetDescriptor();
  }
  static const ::PROTOBUF_NAMESPACE_ID::Descriptor* GetDescriptor() {
    return GetMetadataStatic().descriptor;
  }
  static const ::PROTOBUF_NAMESPACE_ID::Reflection* GetReflection() {
    return GetMetadataStatic().reflection;
  }
  static const BlacklistedAlgorithm& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const BlacklistedAlgorithm* internal_default_instance() {
    return reinterpret_cast<const BlacklistedAlgorithm*>(
               &_BlacklistedAlgorithm_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    1;

  friend void swap(BlacklistedAlgorithm& a, BlacklistedAlgorithm& b) {
    a.Swap(&b);
  }
  inline void Swap(BlacklistedAlgorithm* other) {
    if (other == this) return;
    InternalSwap(other);
  }

  // implements Message ----------------------------------------------

  inline BlacklistedAlgorithm* New() const final {
    return CreateMaybeMessage<BlacklistedAlgorithm>(nullptr);
  }

  BlacklistedAlgorithm* New(::PROTOBUF_NAMESPACE_ID::Arena* arena) const final {
    return CreateMaybeMessage<BlacklistedAlgorithm>(arena);
  }
  void CopyFrom(const ::PROTOBUF_NAMESPACE_ID::Message& from) final;
  void MergeFrom(const ::PROTOBUF_NAMESPACE_ID::Message& from) final;
  void CopyFrom(const BlacklistedAlgorithm& from);
  void MergeFrom(const BlacklistedAlgorithm& from);
  PROTOBUF_ATTRIBUTE_REINITIALIZES void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  #if GOOGLE_PROTOBUF_ENABLE_EXPERIMENTAL_PARSER
  const char* _InternalParse(const char* ptr, ::PROTOBUF_NAMESPACE_ID::internal::ParseContext* ctx) final;
  #else
  bool MergePartialFromCodedStream(
      ::PROTOBUF_NAMESPACE_ID::io::CodedInputStream* input) final;
  #endif  // GOOGLE_PROTOBUF_ENABLE_EXPERIMENTAL_PARSER
  void SerializeWithCachedSizes(
      ::PROTOBUF_NAMESPACE_ID::io::CodedOutputStream* output) const final;
  ::PROTOBUF_NAMESPACE_ID::uint8* InternalSerializeWithCachedSizesToArray(
      ::PROTOBUF_NAMESPACE_ID::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  inline void SharedCtor();
  inline void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(BlacklistedAlgorithm* other);
  friend class ::PROTOBUF_NAMESPACE_ID::internal::AnyMetadata;
  static ::PROTOBUF_NAMESPACE_ID::StringPiece FullMessageName() {
    return "xla.gpu.BlacklistedAlgorithm";
  }
  private:
  inline ::PROTOBUF_NAMESPACE_ID::Arena* GetArenaNoVirtual() const {
    return nullptr;
  }
  inline void* MaybeArenaPtr() const {
    return nullptr;
  }
  public:

  ::PROTOBUF_NAMESPACE_ID::Metadata GetMetadata() const final;
  private:
  static ::PROTOBUF_NAMESPACE_ID::Metadata GetMetadataStatic() {
    ::PROTOBUF_NAMESPACE_ID::internal::AssignDescriptors(&::descriptor_table_tensorflow_2fcompiler_2fxla_2fservice_2fgpu_2fgpu_5fautotuning_2eproto);
    return ::descriptor_table_tensorflow_2fcompiler_2fxla_2fservice_2fgpu_2fgpu_5fautotuning_2eproto.file_level_metadata[kIndexInFileMessages];
  }

  public:

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  enum : int {
    kIdFieldNumber = 1,
    kTensorOpsFieldNumber = 2,
  };
  // int64 id = 1;
  void clear_id();
  ::PROTOBUF_NAMESPACE_ID::int64 id() const;
  void set_id(::PROTOBUF_NAMESPACE_ID::int64 value);

  // bool tensor_ops = 2;
  void clear_tensor_ops();
  bool tensor_ops() const;
  void set_tensor_ops(bool value);

  // @@protoc_insertion_point(class_scope:xla.gpu.BlacklistedAlgorithm)
 private:
  class _Internal;

  ::PROTOBUF_NAMESPACE_ID::internal::InternalMetadataWithArena _internal_metadata_;
  ::PROTOBUF_NAMESPACE_ID::int64 id_;
  bool tensor_ops_;
  mutable ::PROTOBUF_NAMESPACE_ID::internal::CachedSize _cached_size_;
  friend struct ::TableStruct_tensorflow_2fcompiler_2fxla_2fservice_2fgpu_2fgpu_5fautotuning_2eproto;
};
// -------------------------------------------------------------------

class AlgorithmBlacklistEntry :
    public ::PROTOBUF_NAMESPACE_ID::Message /* @@protoc_insertion_point(class_definition:xla.gpu.AlgorithmBlacklistEntry) */ {
 public:
  AlgorithmBlacklistEntry();
  virtual ~AlgorithmBlacklistEntry();

  AlgorithmBlacklistEntry(const AlgorithmBlacklistEntry& from);
  AlgorithmBlacklistEntry(AlgorithmBlacklistEntry&& from) noexcept
    : AlgorithmBlacklistEntry() {
    *this = ::std::move(from);
  }

  inline AlgorithmBlacklistEntry& operator=(const AlgorithmBlacklistEntry& from) {
    CopyFrom(from);
    return *this;
  }
  inline AlgorithmBlacklistEntry& operator=(AlgorithmBlacklistEntry&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }

  static const ::PROTOBUF_NAMESPACE_ID::Descriptor* descriptor() {
    return GetDescriptor();
  }
  static const ::PROTOBUF_NAMESPACE_ID::Descriptor* GetDescriptor() {
    return GetMetadataStatic().descriptor;
  }
  static const ::PROTOBUF_NAMESPACE_ID::Reflection* GetReflection() {
    return GetMetadataStatic().reflection;
  }
  static const AlgorithmBlacklistEntry& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const AlgorithmBlacklistEntry* internal_default_instance() {
    return reinterpret_cast<const AlgorithmBlacklistEntry*>(
               &_AlgorithmBlacklistEntry_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    2;

  friend void swap(AlgorithmBlacklistEntry& a, AlgorithmBlacklistEntry& b) {
    a.Swap(&b);
  }
  inline void Swap(AlgorithmBlacklistEntry* other) {
    if (other == this) return;
    InternalSwap(other);
  }

  // implements Message ----------------------------------------------

  inline AlgorithmBlacklistEntry* New() const final {
    return CreateMaybeMessage<AlgorithmBlacklistEntry>(nullptr);
  }

  AlgorithmBlacklistEntry* New(::PROTOBUF_NAMESPACE_ID::Arena* arena) const final {
    return CreateMaybeMessage<AlgorithmBlacklistEntry>(arena);
  }
  void CopyFrom(const ::PROTOBUF_NAMESPACE_ID::Message& from) final;
  void MergeFrom(const ::PROTOBUF_NAMESPACE_ID::Message& from) final;
  void CopyFrom(const AlgorithmBlacklistEntry& from);
  void MergeFrom(const AlgorithmBlacklistEntry& from);
  PROTOBUF_ATTRIBUTE_REINITIALIZES void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  #if GOOGLE_PROTOBUF_ENABLE_EXPERIMENTAL_PARSER
  const char* _InternalParse(const char* ptr, ::PROTOBUF_NAMESPACE_ID::internal::ParseContext* ctx) final;
  #else
  bool MergePartialFromCodedStream(
      ::PROTOBUF_NAMESPACE_ID::io::CodedInputStream* input) final;
  #endif  // GOOGLE_PROTOBUF_ENABLE_EXPERIMENTAL_PARSER
  void SerializeWithCachedSizes(
      ::PROTOBUF_NAMESPACE_ID::io::CodedOutputStream* output) const final;
  ::PROTOBUF_NAMESPACE_ID::uint8* InternalSerializeWithCachedSizesToArray(
      ::PROTOBUF_NAMESPACE_ID::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  inline void SharedCtor();
  inline void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(AlgorithmBlacklistEntry* other);
  friend class ::PROTOBUF_NAMESPACE_ID::internal::AnyMetadata;
  static ::PROTOBUF_NAMESPACE_ID::StringPiece FullMessageName() {
    return "xla.gpu.AlgorithmBlacklistEntry";
  }
  private:
  inline ::PROTOBUF_NAMESPACE_ID::Arena* GetArenaNoVirtual() const {
    return nullptr;
  }
  inline void* MaybeArenaPtr() const {
    return nullptr;
  }
  public:

  ::PROTOBUF_NAMESPACE_ID::Metadata GetMetadata() const final;
  private:
  static ::PROTOBUF_NAMESPACE_ID::Metadata GetMetadataStatic() {
    ::PROTOBUF_NAMESPACE_ID::internal::AssignDescriptors(&::descriptor_table_tensorflow_2fcompiler_2fxla_2fservice_2fgpu_2fgpu_5fautotuning_2eproto);
    return ::descriptor_table_tensorflow_2fcompiler_2fxla_2fservice_2fgpu_2fgpu_5fautotuning_2eproto.file_level_metadata[kIndexInFileMessages];
  }

  public:

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  enum : int {
    kAlgosFieldNumber = 4,
    kHloFieldNumber = 1,
    kBlasVersionFieldNumber = 5,
    kCcFieldNumber = 2,
    kCudnnVersionFieldNumber = 3,
  };
  // repeated .xla.gpu.BlacklistedAlgorithm algos = 4;
  int algos_size() const;
  void clear_algos();
  ::xla::gpu::BlacklistedAlgorithm* mutable_algos(int index);
  ::PROTOBUF_NAMESPACE_ID::RepeatedPtrField< ::xla::gpu::BlacklistedAlgorithm >*
      mutable_algos();
  const ::xla::gpu::BlacklistedAlgorithm& algos(int index) const;
  ::xla::gpu::BlacklistedAlgorithm* add_algos();
  const ::PROTOBUF_NAMESPACE_ID::RepeatedPtrField< ::xla::gpu::BlacklistedAlgorithm >&
      algos() const;

  // string hlo = 1;
  void clear_hlo();
  const std::string& hlo() const;
  void set_hlo(const std::string& value);
  void set_hlo(std::string&& value);
  void set_hlo(const char* value);
  void set_hlo(const char* value, size_t size);
  std::string* mutable_hlo();
  std::string* release_hlo();
  void set_allocated_hlo(std::string* hlo);

  // string blas_version = 5;
  void clear_blas_version();
  const std::string& blas_version() const;
  void set_blas_version(const std::string& value);
  void set_blas_version(std::string&& value);
  void set_blas_version(const char* value);
  void set_blas_version(const char* value, size_t size);
  std::string* mutable_blas_version();
  std::string* release_blas_version();
  void set_allocated_blas_version(std::string* blas_version);

  // .tensorflow.ComputeCapability cc = 2;
  bool has_cc() const;
  void clear_cc();
  const ::tensorflow::ComputeCapability& cc() const;
  ::tensorflow::ComputeCapability* release_cc();
  ::tensorflow::ComputeCapability* mutable_cc();
  void set_allocated_cc(::tensorflow::ComputeCapability* cc);

  // .tensorflow.CudnnVersion cudnn_version = 3;
  bool has_cudnn_version() const;
  void clear_cudnn_version();
  const ::tensorflow::CudnnVersion& cudnn_version() const;
  ::tensorflow::CudnnVersion* release_cudnn_version();
  ::tensorflow::CudnnVersion* mutable_cudnn_version();
  void set_allocated_cudnn_version(::tensorflow::CudnnVersion* cudnn_version);

  // @@protoc_insertion_point(class_scope:xla.gpu.AlgorithmBlacklistEntry)
 private:
  class _Internal;

  ::PROTOBUF_NAMESPACE_ID::internal::InternalMetadataWithArena _internal_metadata_;
  ::PROTOBUF_NAMESPACE_ID::RepeatedPtrField< ::xla::gpu::BlacklistedAlgorithm > algos_;
  ::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr hlo_;
  ::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr blas_version_;
  ::tensorflow::ComputeCapability* cc_;
  ::tensorflow::CudnnVersion* cudnn_version_;
  mutable ::PROTOBUF_NAMESPACE_ID::internal::CachedSize _cached_size_;
  friend struct ::TableStruct_tensorflow_2fcompiler_2fxla_2fservice_2fgpu_2fgpu_5fautotuning_2eproto;
};
// -------------------------------------------------------------------

class AlgorithmBlacklist :
    public ::PROTOBUF_NAMESPACE_ID::Message /* @@protoc_insertion_point(class_definition:xla.gpu.AlgorithmBlacklist) */ {
 public:
  AlgorithmBlacklist();
  virtual ~AlgorithmBlacklist();

  AlgorithmBlacklist(const AlgorithmBlacklist& from);
  AlgorithmBlacklist(AlgorithmBlacklist&& from) noexcept
    : AlgorithmBlacklist() {
    *this = ::std::move(from);
  }

  inline AlgorithmBlacklist& operator=(const AlgorithmBlacklist& from) {
    CopyFrom(from);
    return *this;
  }
  inline AlgorithmBlacklist& operator=(AlgorithmBlacklist&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }

  static const ::PROTOBUF_NAMESPACE_ID::Descriptor* descriptor() {
    return GetDescriptor();
  }
  static const ::PROTOBUF_NAMESPACE_ID::Descriptor* GetDescriptor() {
    return GetMetadataStatic().descriptor;
  }
  static const ::PROTOBUF_NAMESPACE_ID::Reflection* GetReflection() {
    return GetMetadataStatic().reflection;
  }
  static const AlgorithmBlacklist& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const AlgorithmBlacklist* internal_default_instance() {
    return reinterpret_cast<const AlgorithmBlacklist*>(
               &_AlgorithmBlacklist_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    3;

  friend void swap(AlgorithmBlacklist& a, AlgorithmBlacklist& b) {
    a.Swap(&b);
  }
  inline void Swap(AlgorithmBlacklist* other) {
    if (other == this) return;
    InternalSwap(other);
  }

  // implements Message ----------------------------------------------

  inline AlgorithmBlacklist* New() const final {
    return CreateMaybeMessage<AlgorithmBlacklist>(nullptr);
  }

  AlgorithmBlacklist* New(::PROTOBUF_NAMESPACE_ID::Arena* arena) const final {
    return CreateMaybeMessage<AlgorithmBlacklist>(arena);
  }
  void CopyFrom(const ::PROTOBUF_NAMESPACE_ID::Message& from) final;
  void MergeFrom(const ::PROTOBUF_NAMESPACE_ID::Message& from) final;
  void CopyFrom(const AlgorithmBlacklist& from);
  void MergeFrom(const AlgorithmBlacklist& from);
  PROTOBUF_ATTRIBUTE_REINITIALIZES void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  #if GOOGLE_PROTOBUF_ENABLE_EXPERIMENTAL_PARSER
  const char* _InternalParse(const char* ptr, ::PROTOBUF_NAMESPACE_ID::internal::ParseContext* ctx) final;
  #else
  bool MergePartialFromCodedStream(
      ::PROTOBUF_NAMESPACE_ID::io::CodedInputStream* input) final;
  #endif  // GOOGLE_PROTOBUF_ENABLE_EXPERIMENTAL_PARSER
  void SerializeWithCachedSizes(
      ::PROTOBUF_NAMESPACE_ID::io::CodedOutputStream* output) const final;
  ::PROTOBUF_NAMESPACE_ID::uint8* InternalSerializeWithCachedSizesToArray(
      ::PROTOBUF_NAMESPACE_ID::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  inline void SharedCtor();
  inline void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(AlgorithmBlacklist* other);
  friend class ::PROTOBUF_NAMESPACE_ID::internal::AnyMetadata;
  static ::PROTOBUF_NAMESPACE_ID::StringPiece FullMessageName() {
    return "xla.gpu.AlgorithmBlacklist";
  }
  private:
  inline ::PROTOBUF_NAMESPACE_ID::Arena* GetArenaNoVirtual() const {
    return nullptr;
  }
  inline void* MaybeArenaPtr() const {
    return nullptr;
  }
  public:

  ::PROTOBUF_NAMESPACE_ID::Metadata GetMetadata() const final;
  private:
  static ::PROTOBUF_NAMESPACE_ID::Metadata GetMetadataStatic() {
    ::PROTOBUF_NAMESPACE_ID::internal::AssignDescriptors(&::descriptor_table_tensorflow_2fcompiler_2fxla_2fservice_2fgpu_2fgpu_5fautotuning_2eproto);
    return ::descriptor_table_tensorflow_2fcompiler_2fxla_2fservice_2fgpu_2fgpu_5fautotuning_2eproto.file_level_metadata[kIndexInFileMessages];
  }

  public:

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  enum : int {
    kEntriesFieldNumber = 1,
  };
  // repeated .xla.gpu.AlgorithmBlacklistEntry entries = 1;
  int entries_size() const;
  void clear_entries();
  ::xla::gpu::AlgorithmBlacklistEntry* mutable_entries(int index);
  ::PROTOBUF_NAMESPACE_ID::RepeatedPtrField< ::xla::gpu::AlgorithmBlacklistEntry >*
      mutable_entries();
  const ::xla::gpu::AlgorithmBlacklistEntry& entries(int index) const;
  ::xla::gpu::AlgorithmBlacklistEntry* add_entries();
  const ::PROTOBUF_NAMESPACE_ID::RepeatedPtrField< ::xla::gpu::AlgorithmBlacklistEntry >&
      entries() const;

  // @@protoc_insertion_point(class_scope:xla.gpu.AlgorithmBlacklist)
 private:
  class _Internal;

  ::PROTOBUF_NAMESPACE_ID::internal::InternalMetadataWithArena _internal_metadata_;
  ::PROTOBUF_NAMESPACE_ID::RepeatedPtrField< ::xla::gpu::AlgorithmBlacklistEntry > entries_;
  mutable ::PROTOBUF_NAMESPACE_ID::internal::CachedSize _cached_size_;
  friend struct ::TableStruct_tensorflow_2fcompiler_2fxla_2fservice_2fgpu_2fgpu_5fautotuning_2eproto;
};
// ===================================================================


// ===================================================================

#ifdef __GNUC__
  #pragma GCC diagnostic push
  #pragma GCC diagnostic ignored "-Wstrict-aliasing"
#endif  // __GNUC__
// ConvInstructionLog

// .xla.HloInstructionProto instruction = 1;
inline bool ConvInstructionLog::has_instruction() const {
  return this != internal_default_instance() && instruction_ != nullptr;
}
inline const ::xla::HloInstructionProto& ConvInstructionLog::instruction() const {
  const ::xla::HloInstructionProto* p = instruction_;
  // @@protoc_insertion_point(field_get:xla.gpu.ConvInstructionLog.instruction)
  return p != nullptr ? *p : *reinterpret_cast<const ::xla::HloInstructionProto*>(
      &::xla::_HloInstructionProto_default_instance_);
}
inline ::xla::HloInstructionProto* ConvInstructionLog::release_instruction() {
  // @@protoc_insertion_point(field_release:xla.gpu.ConvInstructionLog.instruction)
  
  ::xla::HloInstructionProto* temp = instruction_;
  instruction_ = nullptr;
  return temp;
}
inline ::xla::HloInstructionProto* ConvInstructionLog::mutable_instruction() {
  
  if (instruction_ == nullptr) {
    auto* p = CreateMaybeMessage<::xla::HloInstructionProto>(GetArenaNoVirtual());
    instruction_ = p;
  }
  // @@protoc_insertion_point(field_mutable:xla.gpu.ConvInstructionLog.instruction)
  return instruction_;
}
inline void ConvInstructionLog::set_allocated_instruction(::xla::HloInstructionProto* instruction) {
  ::PROTOBUF_NAMESPACE_ID::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == nullptr) {
    delete reinterpret_cast< ::PROTOBUF_NAMESPACE_ID::MessageLite*>(instruction_);
  }
  if (instruction) {
    ::PROTOBUF_NAMESPACE_ID::Arena* submessage_arena =
      reinterpret_cast<::PROTOBUF_NAMESPACE_ID::MessageLite*>(instruction)->GetArena();
    if (message_arena != submessage_arena) {
      instruction = ::PROTOBUF_NAMESPACE_ID::internal::GetOwnedMessage(
          message_arena, instruction, submessage_arena);
    }
    
  } else {
    
  }
  instruction_ = instruction;
  // @@protoc_insertion_point(field_set_allocated:xla.gpu.ConvInstructionLog.instruction)
}

// repeated .xla.ShapeProto operand_shapes = 2;
inline int ConvInstructionLog::operand_shapes_size() const {
  return operand_shapes_.size();
}
inline ::xla::ShapeProto* ConvInstructionLog::mutable_operand_shapes(int index) {
  // @@protoc_insertion_point(field_mutable:xla.gpu.ConvInstructionLog.operand_shapes)
  return operand_shapes_.Mutable(index);
}
inline ::PROTOBUF_NAMESPACE_ID::RepeatedPtrField< ::xla::ShapeProto >*
ConvInstructionLog::mutable_operand_shapes() {
  // @@protoc_insertion_point(field_mutable_list:xla.gpu.ConvInstructionLog.operand_shapes)
  return &operand_shapes_;
}
inline const ::xla::ShapeProto& ConvInstructionLog::operand_shapes(int index) const {
  // @@protoc_insertion_point(field_get:xla.gpu.ConvInstructionLog.operand_shapes)
  return operand_shapes_.Get(index);
}
inline ::xla::ShapeProto* ConvInstructionLog::add_operand_shapes() {
  // @@protoc_insertion_point(field_add:xla.gpu.ConvInstructionLog.operand_shapes)
  return operand_shapes_.Add();
}
inline const ::PROTOBUF_NAMESPACE_ID::RepeatedPtrField< ::xla::ShapeProto >&
ConvInstructionLog::operand_shapes() const {
  // @@protoc_insertion_point(field_list:xla.gpu.ConvInstructionLog.operand_shapes)
  return operand_shapes_;
}

// uint64 result_address = 3;
inline void ConvInstructionLog::clear_result_address() {
  result_address_ = PROTOBUF_ULONGLONG(0);
}
inline ::PROTOBUF_NAMESPACE_ID::uint64 ConvInstructionLog::result_address() const {
  // @@protoc_insertion_point(field_get:xla.gpu.ConvInstructionLog.result_address)
  return result_address_;
}
inline void ConvInstructionLog::set_result_address(::PROTOBUF_NAMESPACE_ID::uint64 value) {
  
  result_address_ = value;
  // @@protoc_insertion_point(field_set:xla.gpu.ConvInstructionLog.result_address)
}

// repeated uint64 operand_addresses = 4;
inline int ConvInstructionLog::operand_addresses_size() const {
  return operand_addresses_.size();
}
inline void ConvInstructionLog::clear_operand_addresses() {
  operand_addresses_.Clear();
}
inline ::PROTOBUF_NAMESPACE_ID::uint64 ConvInstructionLog::operand_addresses(int index) const {
  // @@protoc_insertion_point(field_get:xla.gpu.ConvInstructionLog.operand_addresses)
  return operand_addresses_.Get(index);
}
inline void ConvInstructionLog::set_operand_addresses(int index, ::PROTOBUF_NAMESPACE_ID::uint64 value) {
  operand_addresses_.Set(index, value);
  // @@protoc_insertion_point(field_set:xla.gpu.ConvInstructionLog.operand_addresses)
}
inline void ConvInstructionLog::add_operand_addresses(::PROTOBUF_NAMESPACE_ID::uint64 value) {
  operand_addresses_.Add(value);
  // @@protoc_insertion_point(field_add:xla.gpu.ConvInstructionLog.operand_addresses)
}
inline const ::PROTOBUF_NAMESPACE_ID::RepeatedField< ::PROTOBUF_NAMESPACE_ID::uint64 >&
ConvInstructionLog::operand_addresses() const {
  // @@protoc_insertion_point(field_list:xla.gpu.ConvInstructionLog.operand_addresses)
  return operand_addresses_;
}
inline ::PROTOBUF_NAMESPACE_ID::RepeatedField< ::PROTOBUF_NAMESPACE_ID::uint64 >*
ConvInstructionLog::mutable_operand_addresses() {
  // @@protoc_insertion_point(field_mutable_list:xla.gpu.ConvInstructionLog.operand_addresses)
  return &operand_addresses_;
}

// -------------------------------------------------------------------

// BlacklistedAlgorithm

// int64 id = 1;
inline void BlacklistedAlgorithm::clear_id() {
  id_ = PROTOBUF_LONGLONG(0);
}
inline ::PROTOBUF_NAMESPACE_ID::int64 BlacklistedAlgorithm::id() const {
  // @@protoc_insertion_point(field_get:xla.gpu.BlacklistedAlgorithm.id)
  return id_;
}
inline void BlacklistedAlgorithm::set_id(::PROTOBUF_NAMESPACE_ID::int64 value) {
  
  id_ = value;
  // @@protoc_insertion_point(field_set:xla.gpu.BlacklistedAlgorithm.id)
}

// bool tensor_ops = 2;
inline void BlacklistedAlgorithm::clear_tensor_ops() {
  tensor_ops_ = false;
}
inline bool BlacklistedAlgorithm::tensor_ops() const {
  // @@protoc_insertion_point(field_get:xla.gpu.BlacklistedAlgorithm.tensor_ops)
  return tensor_ops_;
}
inline void BlacklistedAlgorithm::set_tensor_ops(bool value) {
  
  tensor_ops_ = value;
  // @@protoc_insertion_point(field_set:xla.gpu.BlacklistedAlgorithm.tensor_ops)
}

// -------------------------------------------------------------------

// AlgorithmBlacklistEntry

// string hlo = 1;
inline void AlgorithmBlacklistEntry::clear_hlo() {
  hlo_.ClearToEmptyNoArena(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited());
}
inline const std::string& AlgorithmBlacklistEntry::hlo() const {
  // @@protoc_insertion_point(field_get:xla.gpu.AlgorithmBlacklistEntry.hlo)
  return hlo_.GetNoArena();
}
inline void AlgorithmBlacklistEntry::set_hlo(const std::string& value) {
  
  hlo_.SetNoArena(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:xla.gpu.AlgorithmBlacklistEntry.hlo)
}
inline void AlgorithmBlacklistEntry::set_hlo(std::string&& value) {
  
  hlo_.SetNoArena(
    &::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:xla.gpu.AlgorithmBlacklistEntry.hlo)
}
inline void AlgorithmBlacklistEntry::set_hlo(const char* value) {
  GOOGLE_DCHECK(value != nullptr);
  
  hlo_.SetNoArena(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:xla.gpu.AlgorithmBlacklistEntry.hlo)
}
inline void AlgorithmBlacklistEntry::set_hlo(const char* value, size_t size) {
  
  hlo_.SetNoArena(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:xla.gpu.AlgorithmBlacklistEntry.hlo)
}
inline std::string* AlgorithmBlacklistEntry::mutable_hlo() {
  
  // @@protoc_insertion_point(field_mutable:xla.gpu.AlgorithmBlacklistEntry.hlo)
  return hlo_.MutableNoArena(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited());
}
inline std::string* AlgorithmBlacklistEntry::release_hlo() {
  // @@protoc_insertion_point(field_release:xla.gpu.AlgorithmBlacklistEntry.hlo)
  
  return hlo_.ReleaseNoArena(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited());
}
inline void AlgorithmBlacklistEntry::set_allocated_hlo(std::string* hlo) {
  if (hlo != nullptr) {
    
  } else {
    
  }
  hlo_.SetAllocatedNoArena(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(), hlo);
  // @@protoc_insertion_point(field_set_allocated:xla.gpu.AlgorithmBlacklistEntry.hlo)
}

// .tensorflow.ComputeCapability cc = 2;
inline bool AlgorithmBlacklistEntry::has_cc() const {
  return this != internal_default_instance() && cc_ != nullptr;
}
inline const ::tensorflow::ComputeCapability& AlgorithmBlacklistEntry::cc() const {
  const ::tensorflow::ComputeCapability* p = cc_;
  // @@protoc_insertion_point(field_get:xla.gpu.AlgorithmBlacklistEntry.cc)
  return p != nullptr ? *p : *reinterpret_cast<const ::tensorflow::ComputeCapability*>(
      &::tensorflow::_ComputeCapability_default_instance_);
}
inline ::tensorflow::ComputeCapability* AlgorithmBlacklistEntry::release_cc() {
  // @@protoc_insertion_point(field_release:xla.gpu.AlgorithmBlacklistEntry.cc)
  
  ::tensorflow::ComputeCapability* temp = cc_;
  cc_ = nullptr;
  return temp;
}
inline ::tensorflow::ComputeCapability* AlgorithmBlacklistEntry::mutable_cc() {
  
  if (cc_ == nullptr) {
    auto* p = CreateMaybeMessage<::tensorflow::ComputeCapability>(GetArenaNoVirtual());
    cc_ = p;
  }
  // @@protoc_insertion_point(field_mutable:xla.gpu.AlgorithmBlacklistEntry.cc)
  return cc_;
}
inline void AlgorithmBlacklistEntry::set_allocated_cc(::tensorflow::ComputeCapability* cc) {
  ::PROTOBUF_NAMESPACE_ID::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == nullptr) {
    delete reinterpret_cast< ::PROTOBUF_NAMESPACE_ID::MessageLite*>(cc_);
  }
  if (cc) {
    ::PROTOBUF_NAMESPACE_ID::Arena* submessage_arena = nullptr;
    if (message_arena != submessage_arena) {
      cc = ::PROTOBUF_NAMESPACE_ID::internal::GetOwnedMessage(
          message_arena, cc, submessage_arena);
    }
    
  } else {
    
  }
  cc_ = cc;
  // @@protoc_insertion_point(field_set_allocated:xla.gpu.AlgorithmBlacklistEntry.cc)
}

// .tensorflow.CudnnVersion cudnn_version = 3;
inline bool AlgorithmBlacklistEntry::has_cudnn_version() const {
  return this != internal_default_instance() && cudnn_version_ != nullptr;
}
inline const ::tensorflow::CudnnVersion& AlgorithmBlacklistEntry::cudnn_version() const {
  const ::tensorflow::CudnnVersion* p = cudnn_version_;
  // @@protoc_insertion_point(field_get:xla.gpu.AlgorithmBlacklistEntry.cudnn_version)
  return p != nullptr ? *p : *reinterpret_cast<const ::tensorflow::CudnnVersion*>(
      &::tensorflow::_CudnnVersion_default_instance_);
}
inline ::tensorflow::CudnnVersion* AlgorithmBlacklistEntry::release_cudnn_version() {
  // @@protoc_insertion_point(field_release:xla.gpu.AlgorithmBlacklistEntry.cudnn_version)
  
  ::tensorflow::CudnnVersion* temp = cudnn_version_;
  cudnn_version_ = nullptr;
  return temp;
}
inline ::tensorflow::CudnnVersion* AlgorithmBlacklistEntry::mutable_cudnn_version() {
  
  if (cudnn_version_ == nullptr) {
    auto* p = CreateMaybeMessage<::tensorflow::CudnnVersion>(GetArenaNoVirtual());
    cudnn_version_ = p;
  }
  // @@protoc_insertion_point(field_mutable:xla.gpu.AlgorithmBlacklistEntry.cudnn_version)
  return cudnn_version_;
}
inline void AlgorithmBlacklistEntry::set_allocated_cudnn_version(::tensorflow::CudnnVersion* cudnn_version) {
  ::PROTOBUF_NAMESPACE_ID::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == nullptr) {
    delete reinterpret_cast< ::PROTOBUF_NAMESPACE_ID::MessageLite*>(cudnn_version_);
  }
  if (cudnn_version) {
    ::PROTOBUF_NAMESPACE_ID::Arena* submessage_arena = nullptr;
    if (message_arena != submessage_arena) {
      cudnn_version = ::PROTOBUF_NAMESPACE_ID::internal::GetOwnedMessage(
          message_arena, cudnn_version, submessage_arena);
    }
    
  } else {
    
  }
  cudnn_version_ = cudnn_version;
  // @@protoc_insertion_point(field_set_allocated:xla.gpu.AlgorithmBlacklistEntry.cudnn_version)
}

// string blas_version = 5;
inline void AlgorithmBlacklistEntry::clear_blas_version() {
  blas_version_.ClearToEmptyNoArena(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited());
}
inline const std::string& AlgorithmBlacklistEntry::blas_version() const {
  // @@protoc_insertion_point(field_get:xla.gpu.AlgorithmBlacklistEntry.blas_version)
  return blas_version_.GetNoArena();
}
inline void AlgorithmBlacklistEntry::set_blas_version(const std::string& value) {
  
  blas_version_.SetNoArena(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:xla.gpu.AlgorithmBlacklistEntry.blas_version)
}
inline void AlgorithmBlacklistEntry::set_blas_version(std::string&& value) {
  
  blas_version_.SetNoArena(
    &::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:xla.gpu.AlgorithmBlacklistEntry.blas_version)
}
inline void AlgorithmBlacklistEntry::set_blas_version(const char* value) {
  GOOGLE_DCHECK(value != nullptr);
  
  blas_version_.SetNoArena(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:xla.gpu.AlgorithmBlacklistEntry.blas_version)
}
inline void AlgorithmBlacklistEntry::set_blas_version(const char* value, size_t size) {
  
  blas_version_.SetNoArena(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:xla.gpu.AlgorithmBlacklistEntry.blas_version)
}
inline std::string* AlgorithmBlacklistEntry::mutable_blas_version() {
  
  // @@protoc_insertion_point(field_mutable:xla.gpu.AlgorithmBlacklistEntry.blas_version)
  return blas_version_.MutableNoArena(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited());
}
inline std::string* AlgorithmBlacklistEntry::release_blas_version() {
  // @@protoc_insertion_point(field_release:xla.gpu.AlgorithmBlacklistEntry.blas_version)
  
  return blas_version_.ReleaseNoArena(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited());
}
inline void AlgorithmBlacklistEntry::set_allocated_blas_version(std::string* blas_version) {
  if (blas_version != nullptr) {
    
  } else {
    
  }
  blas_version_.SetAllocatedNoArena(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(), blas_version);
  // @@protoc_insertion_point(field_set_allocated:xla.gpu.AlgorithmBlacklistEntry.blas_version)
}

// repeated .xla.gpu.BlacklistedAlgorithm algos = 4;
inline int AlgorithmBlacklistEntry::algos_size() const {
  return algos_.size();
}
inline void AlgorithmBlacklistEntry::clear_algos() {
  algos_.Clear();
}
inline ::xla::gpu::BlacklistedAlgorithm* AlgorithmBlacklistEntry::mutable_algos(int index) {
  // @@protoc_insertion_point(field_mutable:xla.gpu.AlgorithmBlacklistEntry.algos)
  return algos_.Mutable(index);
}
inline ::PROTOBUF_NAMESPACE_ID::RepeatedPtrField< ::xla::gpu::BlacklistedAlgorithm >*
AlgorithmBlacklistEntry::mutable_algos() {
  // @@protoc_insertion_point(field_mutable_list:xla.gpu.AlgorithmBlacklistEntry.algos)
  return &algos_;
}
inline const ::xla::gpu::BlacklistedAlgorithm& AlgorithmBlacklistEntry::algos(int index) const {
  // @@protoc_insertion_point(field_get:xla.gpu.AlgorithmBlacklistEntry.algos)
  return algos_.Get(index);
}
inline ::xla::gpu::BlacklistedAlgorithm* AlgorithmBlacklistEntry::add_algos() {
  // @@protoc_insertion_point(field_add:xla.gpu.AlgorithmBlacklistEntry.algos)
  return algos_.Add();
}
inline const ::PROTOBUF_NAMESPACE_ID::RepeatedPtrField< ::xla::gpu::BlacklistedAlgorithm >&
AlgorithmBlacklistEntry::algos() const {
  // @@protoc_insertion_point(field_list:xla.gpu.AlgorithmBlacklistEntry.algos)
  return algos_;
}

// -------------------------------------------------------------------

// AlgorithmBlacklist

// repeated .xla.gpu.AlgorithmBlacklistEntry entries = 1;
inline int AlgorithmBlacklist::entries_size() const {
  return entries_.size();
}
inline void AlgorithmBlacklist::clear_entries() {
  entries_.Clear();
}
inline ::xla::gpu::AlgorithmBlacklistEntry* AlgorithmBlacklist::mutable_entries(int index) {
  // @@protoc_insertion_point(field_mutable:xla.gpu.AlgorithmBlacklist.entries)
  return entries_.Mutable(index);
}
inline ::PROTOBUF_NAMESPACE_ID::RepeatedPtrField< ::xla::gpu::AlgorithmBlacklistEntry >*
AlgorithmBlacklist::mutable_entries() {
  // @@protoc_insertion_point(field_mutable_list:xla.gpu.AlgorithmBlacklist.entries)
  return &entries_;
}
inline const ::xla::gpu::AlgorithmBlacklistEntry& AlgorithmBlacklist::entries(int index) const {
  // @@protoc_insertion_point(field_get:xla.gpu.AlgorithmBlacklist.entries)
  return entries_.Get(index);
}
inline ::xla::gpu::AlgorithmBlacklistEntry* AlgorithmBlacklist::add_entries() {
  // @@protoc_insertion_point(field_add:xla.gpu.AlgorithmBlacklist.entries)
  return entries_.Add();
}
inline const ::PROTOBUF_NAMESPACE_ID::RepeatedPtrField< ::xla::gpu::AlgorithmBlacklistEntry >&
AlgorithmBlacklist::entries() const {
  // @@protoc_insertion_point(field_list:xla.gpu.AlgorithmBlacklist.entries)
  return entries_;
}

#ifdef __GNUC__
  #pragma GCC diagnostic pop
#endif  // __GNUC__
// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------


// @@protoc_insertion_point(namespace_scope)

}  // namespace gpu
}  // namespace xla

// @@protoc_insertion_point(global_scope)

#include <google/protobuf/port_undef.inc>
#endif  // GOOGLE_PROTOBUF_INCLUDED_GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcompiler_2fxla_2fservice_2fgpu_2fgpu_5fautotuning_2eproto
